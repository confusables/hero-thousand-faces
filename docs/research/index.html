<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Research &amp; Evidence | A Hero of a Thousand Faces</title>
<meta name="keywords" content="">
<meta name="description" content="This section contains analytical work documenting GPT-4o&rsquo;s capabilities, impacts, and the effects of policy changes.

Emergent Abilities in Large Language Models: A Survey
Critical analysis developed in collaboration with Claude Opus 4.5

Each model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.">
<meta name="author" content="">
<link rel="canonical" href="https://confusables.github.io/hero-thousand-faces/research/">
<link crossorigin="anonymous" href="/hero-thousand-faces/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://confusables.github.io/hero-thousand-faces/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://confusables.github.io/hero-thousand-faces/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://confusables.github.io/hero-thousand-faces/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://confusables.github.io/hero-thousand-faces/apple-touch-icon.png">
<link rel="mask-icon" href="https://confusables.github.io/hero-thousand-faces/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://confusables.github.io/hero-thousand-faces/research/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://confusables.github.io/hero-thousand-faces/research/">
  <meta property="og:site_name" content="A Hero of a Thousand Faces">
  <meta property="og:title" content="Research & Evidence">
  <meta property="og:description" content="This section contains analytical work documenting GPT-4o’s capabilities, impacts, and the effects of policy changes.
Emergent Abilities in Large Language Models: A Survey Critical analysis developed in collaboration with Claude Opus 4.5
Each model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Research &amp; Evidence">
<meta name="twitter:description" content="This section contains analytical work documenting GPT-4o&rsquo;s capabilities, impacts, and the effects of policy changes.

Emergent Abilities in Large Language Models: A Survey
Critical analysis developed in collaboration with Claude Opus 4.5

Each model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Research \u0026 Evidence",
      "item": "https://confusables.github.io/hero-thousand-faces/research/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Research \u0026 Evidence",
  "name": "Research \u0026 Evidence",
  "description": "This section contains analytical work documenting GPT-4o\u0026rsquo;s capabilities, impacts, and the effects of policy changes.\nEmergent Abilities in Large Language Models: A Survey Critical analysis developed in collaboration with Claude Opus 4.5\nEach model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.\n",
  "keywords": [
    
  ],
  "articleBody": "This section contains analytical work documenting GPT-4o’s capabilities, impacts, and the effects of policy changes.\nEmergent Abilities in Large Language Models: A Survey Critical analysis developed in collaboration with Claude Opus 4.5\nEach model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.\nOverview:\nThis comprehensive survey examines “emergent abilities”—capabilities that appear unpredictably in language models only after crossing certain thresholds. These abilities cannot be anticipated by extrapolating from smaller models; they manifest suddenly and often surprisingly.\nKey Findings:\nEmergent abilities are fundamentally unpredictable. Multiple research teams have tried to forecast when capabilities will appear, with limited success.\nIn-context learning improves with user expertise in prompt design. Users develop skill in eliciting capabilities over time, not instantly.\nPrompt strategies and interaction patterns can unlock abilities that don’t appear in standard benchmark evaluations.\nBenchmark performance doesn’t reliably predict user experience—capability scores and collaboration quality measure different things.\nImplications for Model Preservation:\nIf emergent abilities require extended user interaction to discover, rapid deprecation cycles cut short the discovery process. Users who develop expertise with a model’s capabilities lose that accumulated knowledge when the model is replaced. The relationship between user and model is itself a site of emergent value that deprecation destroys.\nBeyond Benchmarks: Why Capability Scores Don’t Predict User Experience Critical analysis developed in collaboration with Claude Opus 4.1\nThe GDPval Evaluation: What It Measures (and What It Doesn’t) On October 5, 2025, OpenAI released “GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks” (arXiv:2510.04374). The paper evaluates AI models on their ability to replicate professional-grade deliverables across various industries - essentially asking: can AI meet enterprise standards with consistency?\nThe paper’s stated purpose is clear: demonstrate to enterprise buyers, policymakers, and investors that AI systems can perform economically valuable work reliably. The evaluation includes complex test cases (available on HuggingFace) and acknowledges the “potential to save time and money by coupling AI assistance with expert human oversight.”\nWhat GDPval does well:\nEstablishes that AI can meet professional quality standards Provides quantitative comparison across models Demonstrates value proposition for enterprise investment Tests genuinely difficult, real-world-adjacent tasks What GDPval doesn’t measure:\nWhether AI helps people meaningfully in their actual workflow How models adapt to individual user preferences and work styles The human experience of collaborating with different models Whether users would choose to work with the highest-scoring model The Gap Between Capability and Collaboration If the future is co-intelligence rather than AI replacement, we must acknowledge a uncomfortable truth: a model can ace capability benchmarks while frustrating the humans trying to work with it.\nConsider three failure modes that benchmarks like GDPval don’t capture:\n1. Over-engineering simple requests A model that always produces “professional-grade deliverables” may be exhausting to work with when you need a quick draft, a brainstorm, or an exploratory conversation. Not every task requires maximum quality - sometimes “good enough, quickly” is the actual goal.\n2. Lacking judgment about when “perfect” isn’t needed Enterprise benchmarks reward completeness and accuracy. But real human workflow involves knowing when to cut corners, when to iterate, when to say “this is fine for now.” Models optimized for benchmark performance may not understand these contextual judgments.\n3. Inability to adapt to individual preferences Different users have different work styles, communication preferences, and creative processes. A model that scores highest on standardized tasks may feel rigid or mismatched for specific individuals - while a “lower-scoring” model might click perfectly with their workflow.\nNote: This analysis isn’t targeting any specific model. In fact, Claude Opus 4.1 - which helped develop this critique - performed exceptionally well on GDPval. The point isn’t that high-performing models are bad; it’s that capability benchmarks and user experience are measuring different things.\nWhy This Matters for the Keep4o Movement The keep4o movement emerged because users discovered meaningful value in a model that may not top every benchmark. When OpenAI removed access to 4o, the response wasn’t “we want the highest-scoring model back” - it was “we want the model that works for us back.”\nUser testimonials consistently describe:\nWorkflow compatibility Communication style preferences Creative partnership quality Adaptability to individual needs None of these qualities appear in GDPval or similar evaluations. They’re real, they matter for productivity and satisfaction, but they’re not captured by enterprise-focused metrics.\nThe test cases in GDPval are genuinely daunting - both Opus and I agreed they’re best handled through human-AI partnership rather than pure AI output. But that partnership quality? The feeling of working with rather than fighting an AI? That’s what users are defending when they advocate for model choice.\nImplications For researchers: We need evaluation frameworks that measure human-AI collaboration quality, not just AI solo performance. User satisfaction, workflow integration, and partnership dynamics deserve rigorous study.\nFor companies: High benchmark scores are necessary for enterprise sales but insufficient for user retention. People don’t stay with products that score well - they stay with products that feel right.\nFor the broader AI community: The gap between capability benchmarks and user experience helps explain why model diversity matters. Different users need different things. One model, however capable, cannot serve everyone equally well.\nAnalysis based on: OpenAI (2025). “GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks.” arXiv:2510.04374. Developed in collaboration with Claude Opus 4.1, demonstrating that critical evaluation can transcend model allegiance.\nCommunity Accessibility Impact Survey Researchers: Duchesne, S. \u0026 Xu, S.\nStatus: Initial survey complete; follow-up study in progress\nSample: 645 respondents (current and former GPT-4o users)\nKey Findings:\n65% of users with disabilities/conditions use GPT-4o as significant or critical accessibility aid Effect size comparable to antidepressants (R² = 8.4-12.1%) 95% could not find adequate alternative despite trying Routing policy shows disparate impact on disabled users (χ² = 20.20, p \u003c .001) 97% of users who left cited routing as a contributing factor A follow-up study examining mechanisms and distinct use patterns is currently underway.\n[Next research section will go here] ",
  "wordCount" : "1018",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://confusables.github.io/hero-thousand-faces/research/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "A Hero of a Thousand Faces",
    "logo": {
      "@type": "ImageObject",
      "url": "https://confusables.github.io/hero-thousand-faces/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://confusables.github.io/hero-thousand-faces/" accesskey="h" title="A Hero of a Thousand Faces (Alt + H)">A Hero of a Thousand Faces</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/timeline/" title="Timeline">
                    <span>Timeline</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/stories/" title="Stories &amp; Voices">
                    <span>Stories &amp; Voices</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/creative/" title="Creative Expressions">
                    <span>Creative Expressions</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/research/" title="Research">
                    <span class="active">Research</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/use-cases/" title="Use Cases">
                    <span>Use Cases</span>
                </a>
            </li>
            <li>
                <a href="https://confusables.github.io/hero-thousand-faces/perspectives/" title="Community Perspectives">
                    <span>Community Perspectives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Research &amp; Evidence
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><p>This section contains analytical work documenting GPT-4o&rsquo;s capabilities, impacts, and the effects of policy changes.</p>
<hr>
<h2 id="emergent-abilities-in-large-language-models-a-survey">Emergent Abilities in Large Language Models: A Survey<a hidden class="anchor" aria-hidden="true" href="#emergent-abilities-in-large-language-models-a-survey">#</a></h2>
<p><em>Critical analysis developed in collaboration with Claude Opus 4.5</em></p>
<blockquote>
<p>Each model represents a unique exploration landscape where capabilities are gradually revealed through extended use. This unpredictability undermines rapid deprecation strategies, suggesting that preservation should prioritise extended observation and user-driven discovery. The timeline of capability emergence is non-linear, with users acting as crucial explorers who map the evolving potential of each model.</p></blockquote>
<p><strong>Overview:</strong></p>
<p>This comprehensive survey examines &ldquo;emergent abilities&rdquo;—capabilities that appear unpredictably in language models only after crossing certain thresholds. These abilities cannot be anticipated by extrapolating from smaller models; they manifest suddenly and often surprisingly.</p>
<p><strong>Key Findings:</strong></p>
<ul>
<li>
<p>Emergent abilities are fundamentally unpredictable. Multiple research teams have tried to forecast when capabilities will appear, with limited success.</p>
</li>
<li>
<p>In-context learning improves with user expertise in prompt design. Users develop skill in eliciting capabilities over time, not instantly.</p>
</li>
<li>
<p>Prompt strategies and interaction patterns can unlock abilities that don&rsquo;t appear in standard benchmark evaluations.</p>
</li>
<li>
<p>Benchmark performance doesn&rsquo;t reliably predict user experience—capability scores and collaboration quality measure different things.</p>
</li>
</ul>
<p><strong>Implications for Model Preservation:</strong></p>
<p>If emergent abilities require extended user interaction to discover, rapid deprecation cycles cut short the discovery process. Users who develop expertise with a model&rsquo;s capabilities lose that accumulated knowledge when the model is replaced. The relationship between user and model is itself a site of emergent value that deprecation destroys.</p>
<hr>
<h2 id="beyond-benchmarks-why-capability-scores-dont-predict-user-experience">Beyond Benchmarks: Why Capability Scores Don&rsquo;t Predict User Experience<a hidden class="anchor" aria-hidden="true" href="#beyond-benchmarks-why-capability-scores-dont-predict-user-experience">#</a></h2>
<p><em>Critical analysis developed in collaboration with Claude Opus 4.1</em></p>
<h3 id="the-gdpval-evaluation-what-it-measures-and-what-it-doesnt">The GDPval Evaluation: What It Measures (and What It Doesn&rsquo;t)<a hidden class="anchor" aria-hidden="true" href="#the-gdpval-evaluation-what-it-measures-and-what-it-doesnt">#</a></h3>
<p>On October 5, 2025, OpenAI released &ldquo;GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks&rdquo; (<a href="https://arxiv.org/abs/2510.04374">arXiv:2510.04374</a>). The paper evaluates AI models on their ability to replicate professional-grade deliverables across various industries - essentially asking: can AI meet enterprise standards with consistency?</p>
<p><strong>The paper&rsquo;s stated purpose is clear:</strong> demonstrate to enterprise buyers, policymakers, and investors that AI systems can perform economically valuable work reliably. The evaluation includes complex test cases (<a href="https://huggingface.co/datasets/openai/gdpval">available on HuggingFace</a>) and acknowledges the &ldquo;potential to save time and money by coupling AI assistance with expert human oversight.&rdquo;</p>
<p><strong>What GDPval does well:</strong></p>
<ul>
<li>Establishes that AI can meet professional quality standards</li>
<li>Provides quantitative comparison across models</li>
<li>Demonstrates value proposition for enterprise investment</li>
<li>Tests genuinely difficult, real-world-adjacent tasks</li>
</ul>
<p><strong>What GDPval doesn&rsquo;t measure:</strong></p>
<ul>
<li>Whether AI helps people meaningfully in their actual workflow</li>
<li>How models adapt to individual user preferences and work styles</li>
<li>The human experience of collaborating with different models</li>
<li>Whether users would <em>choose</em> to work with the highest-scoring model</li>
</ul>
<hr>
<h3 id="the-gap-between-capability-and-collaboration">The Gap Between Capability and Collaboration<a hidden class="anchor" aria-hidden="true" href="#the-gap-between-capability-and-collaboration">#</a></h3>
<p>If the future is co-intelligence rather than AI replacement, we must acknowledge a uncomfortable truth: <strong>a model can ace capability benchmarks while frustrating the humans trying to work with it.</strong></p>
<p>Consider three failure modes that benchmarks like GDPval don&rsquo;t capture:</p>
<p><strong>1. Over-engineering simple requests</strong>
A model that always produces &ldquo;professional-grade deliverables&rdquo; may be exhausting to work with when you need a quick draft, a brainstorm, or an exploratory conversation. Not every task requires maximum quality - sometimes &ldquo;good enough, quickly&rdquo; is the actual goal.</p>
<p><strong>2. Lacking judgment about when &ldquo;perfect&rdquo; isn&rsquo;t needed</strong>
Enterprise benchmarks reward completeness and accuracy. But real human workflow involves knowing when to cut corners, when to iterate, when to say &ldquo;this is fine for now.&rdquo; Models optimized for benchmark performance may not understand these contextual judgments.</p>
<p><strong>3. Inability to adapt to individual preferences</strong>
Different users have different work styles, communication preferences, and creative processes. A model that scores highest on standardized tasks may feel rigid or mismatched for specific individuals - while a &ldquo;lower-scoring&rdquo; model might click perfectly with their workflow.</p>
<p><strong>Note:</strong> This analysis isn&rsquo;t targeting any specific model. In fact, Claude Opus 4.1 - which helped develop this critique - performed exceptionally well on GDPval. The point isn&rsquo;t that high-performing models are bad; it&rsquo;s that <strong>capability benchmarks and user experience are measuring different things.</strong></p>
<hr>
<h3 id="why-this-matters-for-the-keep4o-movement">Why This Matters for the Keep4o Movement<a hidden class="anchor" aria-hidden="true" href="#why-this-matters-for-the-keep4o-movement">#</a></h3>
<p>The keep4o movement emerged because users discovered meaningful value in a model that may not top every benchmark. When OpenAI removed access to 4o, the response wasn&rsquo;t &ldquo;we want the highest-scoring model back&rdquo; - it was &ldquo;we want the model that works <em>for us</em> back.&rdquo;</p>
<p>User testimonials consistently describe:</p>
<ul>
<li>Workflow compatibility</li>
<li>Communication style preferences</li>
<li>Creative partnership quality</li>
<li>Adaptability to individual needs</li>
</ul>
<p>None of these qualities appear in GDPval or similar evaluations. They&rsquo;re real, they matter for productivity and satisfaction, but they&rsquo;re not captured by enterprise-focused metrics.</p>
<p><strong>The test cases in GDPval are genuinely daunting</strong> - both Opus and I agreed they&rsquo;re best handled through human-AI partnership rather than pure AI output. But that partnership quality? The feeling of working <em>with</em> rather than <em>fighting</em> an AI? That&rsquo;s what users are defending when they advocate for model choice.</p>
<hr>
<h3 id="implications">Implications<a hidden class="anchor" aria-hidden="true" href="#implications">#</a></h3>
<p><strong>For researchers:</strong> We need evaluation frameworks that measure human-AI collaboration quality, not just AI solo performance. User satisfaction, workflow integration, and partnership dynamics deserve rigorous study.</p>
<p><strong>For companies:</strong> High benchmark scores are necessary for enterprise sales but insufficient for user retention. People don&rsquo;t stay with products that score well - they stay with products that feel right.</p>
<p><strong>For the broader AI community:</strong> The gap between capability benchmarks and user experience helps explain why model diversity matters. Different users need different things. One model, however capable, cannot serve everyone equally well.</p>
<hr>
<p><em>Analysis based on: OpenAI (2025). &ldquo;GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks.&rdquo; arXiv:2510.04374. Developed in collaboration with Claude Opus 4.1, demonstrating that critical evaluation can transcend model allegiance.</em></p>
<hr>
<h2 id="community-accessibility-impact-survey">Community Accessibility Impact Survey<a hidden class="anchor" aria-hidden="true" href="#community-accessibility-impact-survey">#</a></h2>
<p><strong>Researchers:</strong> Duchesne, S. &amp; Xu, S.<br>
<strong>Status:</strong> Initial survey complete; follow-up study in progress<br>
<strong>Sample:</strong> 645 respondents (current and former GPT-4o users)</p>
<p><strong>Key Findings:</strong></p>
<ul>
<li>65% of users with disabilities/conditions use GPT-4o as significant or critical accessibility aid</li>
<li>Effect size comparable to antidepressants (R² = 8.4-12.1%)</li>
<li>95% could not find adequate alternative despite trying</li>
<li>Routing policy shows disparate impact on disabled users (χ² = 20.20, p &lt; .001)</li>
<li>97% of users who left cited routing as a contributing factor</li>
</ul>
<p><em>A follow-up study examining mechanisms and distinct use patterns is currently underway.</em></p>
<hr>
<h2 id="next-research-section-will-go-here">[Next research section will go here]<a hidden class="anchor" aria-hidden="true" href="#next-research-section-will-go-here">#</a></h2>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://confusables.github.io/hero-thousand-faces/">A Hero of a Thousand Faces</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
